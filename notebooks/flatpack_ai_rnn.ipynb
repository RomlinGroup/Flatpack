{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/romlingroup/flatpack-ai/blob/main/notebooks/flatpack_ai_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# flatpack.ai - RNN\n",
    "This Colab notebook demonstrates how to train a Recurrent Neural Network (RNN) on a text dataset and then use the trained model to generate new text sequences. The model is trained character by character, learning the patterns and structure of the input text, and can then generate coherent and contextually relevant text sequences.\n",
    "\n",
    "https://github.com/romlingroup/flatpack-ai"
   ],
   "metadata": {
    "id": "g3x8ittAimlh"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4X8HdQdeAOg"
   },
   "outputs": [],
   "source": [
    "!pip uninstall flatpack -y\n",
    "!pip install flatpack"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from flatpack import datasets, instructions, models\n",
    "\n",
    "# Download the text and create a character set and indexed text\n",
    "text_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "text = datasets.download_text(text_url)[:10000]\n",
    "chars = sorted(set(text))\n",
    "indexed_text = [chars.index(char) for char in text]\n",
    "\n",
    "# Create char_to_index and index_to_char mappings\n",
    "char_to_index = {char: i for i, char in enumerate(chars)}\n",
    "index_to_char = {i: char for i, char in enumerate(chars)}\n",
    "\n",
    "# Initialize the custom dataset and train the RNN model\n",
    "instructions.build(\n",
    "    user_train_function=lambda epochs, batch_size: models.RNNLM.train_model(\n",
    "        dataset=datasets.TextDataset(indexed_text, seq_length=64),\n",
    "        vocab_size=len(chars),\n",
    "        embed_size=32,\n",
    "        hidden_size=128,\n",
    "        num_layers=4,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size\n",
    "    ),\n",
    "    save_dir='/content/saved_model',\n",
    "    char_to_index=char_to_index,\n",
    "    index_to_char=index_to_char,\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    framework='pytorch',\n",
    "    model_type='rnn'\n",
    ")"
   ],
   "metadata": {
    "id": "3ZE4Q9YKSHmn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from flatpack import models\n",
    "\n",
    "EMBED_SIZE = 32\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 4\n",
    "SAVE_DIR = '/content/saved_model'\n",
    "MODEL_PATH = f'{SAVE_DIR}/rnn_model.pth'\n",
    "GENERATE_LENGTH = 1024\n",
    "TEMPERATURE = 1.0\n",
    "\n",
    "model = models.RNN(EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS)\n",
    "model.load_vocab_size(SAVE_DIR)\n",
    "model.load_state_dict(models.RNN.load_torch_model(MODEL_PATH))\n",
    "generated_text = model.generate_text(SAVE_DIR, start_sequence=\"To be, or not to be\", generate_length=GENERATE_LENGTH, temperature=TEMPERATURE)\n",
    "\n",
    "print(\"Generated text:\", generated_text)"
   ],
   "metadata": {
    "id": "H1kvzt3kuc_1"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "authorship_tag": "ABX9TyNe/hcnFbYMTxpEv6P0boQk",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
