{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romlingroup/flatpack-ai/blob/main/notebooks/flatpack_ai_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# flatpack.ai - RNN\n",
        "This Colab notebook demonstrates how to train a Recurrent Neural Network (RNN) on a text dataset and then use the trained model to generate new text sequences. The model is trained character by character, learning the patterns and structure of the input text, and can then generate coherent and contextually relevant text sequences.\n",
        "\n",
        "https://github.com/romlingroup/flatpack-ai"
      ],
      "metadata": {
        "id": "g3x8ittAimlh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4X8HdQdeAOg"
      },
      "outputs": [],
      "source": [
        "!pip uninstall flatpack -y\n",
        "!pip install flatpack"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flatpack import datasets, instructions, models, utils\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "dataset, char_to_index, index_to_char = prepare_text_dataset(url, seq_length=64, subset_size=1000)\n",
        "device = utils.configure_device()\n",
        "\n",
        "user_train_function = lambda epochs, batch_size: models.RNN.train_model(\n",
        "    batch_size=batch_size,\n",
        "    dataset=dataset,\n",
        "    device=device,\n",
        "    embed_size=32,\n",
        "    epochs=epochs,\n",
        "    hidden_size=128,\n",
        "    num_layers=4,\n",
        "    vocab_size=len(char_to_index)\n",
        ")\n",
        "\n",
        "instructions.build(\n",
        "    batch_size=128,\n",
        "    epochs=10,\n",
        "    save_dir='/content/saved_model',\n",
        "    user_train_function=user_train_function,\n",
        "    url=url\n",
        ")"
      ],
      "metadata": {
        "id": "3ZE4Q9YKSHmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "from flatpack import models\n",
        "\n",
        "random.seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.RNN(32, 128, 4).to(device)\n",
        "model.load_vocab_size('/content/saved_model')\n",
        "model.load_state_dict(models.RNN.load_torch_model('/content/saved_model/rnn_model.pth'))\n",
        "model.embedding, model.rnn, model.fc = model.embedding.to(device), model.rnn.to(device), model.fc.to(device)\n",
        "\n",
        "print(\"Generated text:\", model.generate_text('/content/saved_model', start_sequence=\"To be, or not to be\", generate_length=1024, temperature=1.0, device=device))"
      ],
      "metadata": {
        "id": "H1kvzt3kuc_1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}