{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romlingroup/flatpack-ai/blob/main/notebooks/flatpack_ai_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# flatpack.ai - RNN\n",
        "This Colab notebook demonstrates how to train a Recurrent Neural Network (RNN) on a text dataset and then use the trained model to generate new text sequences. The model is trained character by character, learning the patterns and structure of the input text, and can then generate coherent and contextually relevant text sequences.\n",
        "\n",
        "https://github.com/romlingroup/flatpack-ai"
      ],
      "metadata": {
        "id": "g3x8ittAimlh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4X8HdQdeAOg"
      },
      "outputs": [],
      "source": [
        "!pip uninstall flatpack -y\n",
        "!pip install flatpack"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from flatpack import datasets, instructions, models\n",
        "\n",
        "text = datasets.download_text(\"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\")[:100000]\n",
        "chars = sorted(set(text))\n",
        "indexed_text = [chars.index(char) for char in text]\n",
        "char_to_index = {char: i for i, char in enumerate(chars)}\n",
        "index_to_char = {i: char for i, char in enumerate(chars)}\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "instructions.build(\n",
        "    batch_size=128,\n",
        "    char_to_index=char_to_index,\n",
        "    device=device,\n",
        "    epochs=10,\n",
        "    framework='pytorch',\n",
        "    index_to_char=index_to_char,\n",
        "    model_type='rnn',\n",
        "    save_dir='/content/saved_model',\n",
        "    user_train_function=lambda epochs, batch_size: models.RNN.train_model(\n",
        "        batch_size=batch_size,\n",
        "        dataset=datasets.TextDataset(indexed_text, seq_length=64),\n",
        "        device=device,\n",
        "        embed_size=32,\n",
        "        epochs=epochs,\n",
        "        hidden_size=128,\n",
        "        num_layers=4,\n",
        "        vocab_size=len(chars),\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "3ZE4Q9YKSHmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "from flatpack import models\n",
        "\n",
        "random.seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.RNN(32, 128, 4).to(device)\n",
        "model.load_vocab_size('/content/saved_model')\n",
        "model.load_state_dict(models.RNN.load_torch_model('/content/saved_model/rnn_model.pth'))\n",
        "model.embedding, model.rnn, model.fc = model.embedding.to(device), model.rnn.to(device), model.fc.to(device)\n",
        "\n",
        "print(\"Generated text:\", model.generate_text('/content/saved_model', start_sequence=\"To be, or not to be\", generate_length=1024, temperature=1.0, device=device))"
      ],
      "metadata": {
        "id": "H1kvzt3kuc_1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}