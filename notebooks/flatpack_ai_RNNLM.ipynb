{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romlingroup/flatpack-ai/blob/main/notebooks/flatpack_ai_RNNLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4X8HdQdeAOg",
        "outputId": "d8aab556-f082-4dd1-e1f6-96c640d216cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping flatpack as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting flatpack\n",
            "  Downloading flatpack-0.5.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flatpack) (2.31.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from flatpack) (0.10.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flatpack) (2.0.1+cu118)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flatpack) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flatpack) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flatpack) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flatpack) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flatpack) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->flatpack) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flatpack) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flatpack) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flatpack) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->flatpack) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->flatpack) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->flatpack) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flatpack) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flatpack) (1.3.0)\n",
            "Installing collected packages: flatpack\n",
            "Successfully installed flatpack-0.5.4\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall flatpack -y\n",
        "!pip install flatpack"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flatpack import datasets, instructions, models\n",
        "\n",
        "# Download the text and create a character set and indexed text\n",
        "text_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "text = datasets.download_text(text_url)[:10000]\n",
        "chars = sorted(set(text))\n",
        "indexed_text = [chars.index(char) for char in text]\n",
        "\n",
        "# Create char_to_index and index_to_char mappings\n",
        "char_to_index = {char: i for i, char in enumerate(chars)}\n",
        "index_to_char = {i: char for i, char in enumerate(chars)}\n",
        "\n",
        "# Initialize the custom dataset and train the RNN model\n",
        "instructions.build(\n",
        "    user_train_function=lambda epochs, batch_size: models.RNNLM.train_model(\n",
        "        dataset=datasets.TextDataset(indexed_text, seq_length=64),\n",
        "        vocab_size=len(chars),\n",
        "        embed_size=32,\n",
        "        hidden_size=128,\n",
        "        num_layers=4,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size\n",
        "    ),\n",
        "    save_dir='/content/saved_model',\n",
        "    char_to_index=char_to_index,\n",
        "    index_to_char=index_to_char,\n",
        "    batch_size=128,\n",
        "    epochs=10,\n",
        "    framework='pytorch',\n",
        "    model_type='rnn'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZE4Q9YKSHmn",
        "outputId": "90cb7a58-efba-4dc1-cfaf-2023cd58c696"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Training rnn model with epochs: 10 and batch_size: 128\n",
            "Epoch 1/10, Loss: 2.9714, Accuracy: 0.2230\n",
            "Epoch 2/10, Loss: 2.0768, Accuracy: 0.4203\n",
            "Epoch 3/10, Loss: 1.6555, Accuracy: 0.5268\n",
            "Epoch 4/10, Loss: 1.3132, Accuracy: 0.6243\n",
            "Epoch 5/10, Loss: 0.9883, Accuracy: 0.7282\n",
            "Epoch 6/10, Loss: 0.7063, Accuracy: 0.8238\n",
            "Epoch 7/10, Loss: 0.5057, Accuracy: 0.8903\n",
            "Epoch 8/10, Loss: 0.3843, Accuracy: 0.9219\n",
            "Epoch 9/10, Loss: 0.3146, Accuracy: 0.9348\n",
            "Epoch 10/10, Loss: 0.2739, Accuracy: 0.9404\n",
            "âœ… Training completed in 64.16 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flatpack import models\n",
        "\n",
        "EMBED_SIZE = 32\n",
        "HIDDEN_SIZE = 128\n",
        "NUM_LAYERS = 4\n",
        "SAVE_DIR = '/content/saved_model'\n",
        "MODEL_PATH = f'{SAVE_DIR}/rnn_model.pth'\n",
        "GENERATE_LENGTH = 1024\n",
        "TEMPERATURE = 1.0\n",
        "\n",
        "model = models.RNNLM(EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS)\n",
        "model.load_vocab_size(SAVE_DIR)\n",
        "model.load_state_dict(models.RNNLM.load_torch_model(MODEL_PATH))\n",
        "generated_text = model.generate_text(SAVE_DIR, start_sequence=\"To be, or not to be\", generate_length=GENERATE_LENGTH, temperature=TEMPERATURE)\n",
        "\n",
        "print(\"Generated text:\", generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1kvzt3kuc_1",
        "outputId": "3bbb5aa8-05b6-4c9c-a8a1-efaf56af18b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: To be, or not to beless yourselves wondecte urs go'ds in afmeat on\n",
            "Would you proceed especially against Carus,\n",
            "Epes you malign our seedipliots of mance.\n",
            "\n",
            "MENENIUS:\n",
            "For that in state, whose course will on\n",
            "The way it takes, cime funse; and their stave jt suffering stroughes on where more bouds the other trave belly was deliberate,\n",
            "And cares: is retinge, wouds the erots on Cveic it.\n",
            "\n",
            "MENENIUSy\n",
            "A seck use,\n",
            "Of triends, manes woudlly speade.\n",
            "Hail: but speak not malicious?\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rake freancess in no way say he so med us\n",
            "Oell high as fictter in rime, we aresuras to\n",
            "ghome't, me unal you.\n",
            "\n",
            "We should bats and clubs:\n",
            "Your belly's answer? what me sere\n",
            "poor\n",
            "suitnius?\n",
            "\n",
            "First Citizen:\n",
            "We, you.\n",
            "\n",
            "First Citizen:\n",
            "You are all reselloes? cour fit it tost bakrins.\n",
            "\n",
            "First Citizen:\n",
            "Very well; andUcyeyeir,\n",
            "Our steed these They say wow mat'ly inceinor with the rest, where the other instruments\n",
            "Did see and heally, in one:\n",
            "With eity,\n",
            "bes,\n",
            "HimEeI\n",
            "Stall--\n",
            "Their counsels and their stattled; this as ly.\n",
            "\n",
            "AMd:\n",
            "Sfictt\n",
            "They are diss\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMqqOMTNAFT/y9/yiM7gv6n",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}