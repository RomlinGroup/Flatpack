{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMd08P12VmXtQDlBgi7JjrN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romlingroup/flatpack-ai/blob/main/notebooks/flatpack_ai_autotrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# flatpack.ai - AutoTrain by Hugging Face\n",
        "https://huggingface.co/autotrain"
      ],
      "metadata": {
        "id": "w6HuNp6HNPI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas autotrain-advanced -q\n",
        "!autotrain setup --update-torch\n",
        "!mkdir /content/data"
      ],
      "metadata": {
        "id": "op9YoeVtJ75A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload train.csv containing a \"text\" column to /content/data in Colab."
      ],
      "metadata": {
        "id": "xHUyRBnYNGmH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFaYbjh8Jh4i"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = 'gpt2_autotrain'\n",
        "os.environ[\"MODEL_NAME\"] = 'gpt2'\n",
        "\n",
        "os.environ[\"PUSH_TO_HUB\"] = 'False'\n",
        "os.environ[\"HF_TOKEN\"] = \"hf_XXX\"\n",
        "os.environ[\"REPO_ID\"] = \"username/repo_name\"\n",
        "\n",
        "os.environ[\"LEARNING_RATE\"] = '2e-4'\n",
        "os.environ[\"NUM_EPOCHS\"] = '1'\n",
        "os.environ[\"BATCH_SIZE\"] = '1'\n",
        "os.environ[\"BLOCK_SIZE\"] = '1024'\n",
        "os.environ[\"WARMUP_RATIO\"] = '0.1'\n",
        "os.environ[\"WEIGHT_DECAY\"] = '0.01'\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = '4'\n",
        "os.environ[\"USE_FP16\"] = 'True'\n",
        "os.environ[\"USE_PEFT\"] = 'True'\n",
        "os.environ[\"USE_INT4\"] = 'True'\n",
        "os.environ[\"LORA_R\"] = '16'\n",
        "os.environ[\"LORA_ALPHA\"] = '32'\n",
        "os.environ[\"LORA_DROPOUT\"] = '0.05'\n",
        "\n",
        "command = '''!autotrain llm \\\\\n",
        "--train \\\\\n",
        "--model ${MODEL_NAME} \\\\\n",
        "--project-name ${PROJECT_NAME} \\\\\n",
        "--data-path data/ \\\\\n",
        "--text-column text \\\\\n",
        "--lr ${LEARNING_RATE} \\\\\n",
        "--batch-size ${BATCH_SIZE} \\\\\n",
        "--epochs ${NUM_EPOCHS} \\\\\n",
        "--block-size ${BLOCK_SIZE} \\\\\n",
        "--warmup-ratio ${WARMUP_RATIO} \\\\\n",
        "--lora-r ${LORA_R} \\\\\n",
        "--lora-alpha ${LORA_ALPHA} \\\\\n",
        "--lora-dropout ${LORA_DROPOUT} \\\\\n",
        "--weight-decay ${WEIGHT_DECAY} \\\\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\\\n",
        "$( [[ \"$USE_FP16\" == \"True\" ]] && echo \"--fp16\" ) \\\\\n",
        "$( [[ \"$USE_PEFT\" == \"True\" ]] && echo \"--use-peft\" ) \\\\\n",
        "$( [[ \"$USE_INT4\" == \"True\" ]] && echo \"--use-int4\" ) \\\\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN} --repo-id ${REPO_ID}\" )'''\n",
        "\n",
        "print(command)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the printed command into a new Colab cell and execute it."
      ],
      "metadata": {
        "id": "C6gII8VYN6TM"
      }
    }
  ]
}