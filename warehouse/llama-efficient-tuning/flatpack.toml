# flatpack.toml
# WIP (2023-09-04)

version = "0.0.1"
base_image = "debian:stable-slim"

[environment]
model_name = "llama-efficient-tuning"

[[port]]
external = 1337
internal = 80

[directories]
checkpoints = "/home/content/checkpoints"
data = "/home/content/data"
models = "/home/content/models"
scripts = "/home/content/scripts"

[packages]

[packages.unix]
gcc = "*"
git = "*"
python3-pip = "*"
wget = "*"

[packages.python]
datasets = "*"
numpy = "*"
tiktoken = "*"
transformers = "*"
torch = "*"
tqdm = "*"
wandb = "*"

[[git]]
from_source = "https://github.com/romlingroup/LLaMA-Efficient-Tuning"
to_destination = "/home/content/LLaMA-Efficient-Tuning"
branch = "master"

[[file]]
from_source = "https://raw.githubusercontent.com/romlingroup/flatpack-ai/main/warehouse/llama-efficient-tuning/train.sh"
to_destination = "/home/content/train.sh"

[[run]]
command = "chmod"
args = "+x /home/content/train.sh"

[[cmd]]
command = "bash"
args = "/home/content/train.sh"