# flatpack.toml
# WIP ({{current_date}})

version = "0.0.1"

[environment]
model_name = "llama-cpp"
python_version = "3.12"

[[port]]
external = 8080
internal = 80

[directories]
checkpoints = "checkpoints"
data = "data"
models = "models"
scripts = "scripts"

[packages]

[packages.unix]
build-essential = "*"
cmake = "*"
gcc = "*"
git = "*"
jq = "*"
python3-dev = "*"
python3-pip = "*"
sox = "*"
wget = "*"

[packages.python]
kokoro-onnx = "0.1.9"
numpy = "2.2.0"
soundfile = "0.13.0"
tiktoken = "0.8.0"
tqdm = "4.67.1"

# [[git]]
# from_source = "{{git_source_url}}"
# to_destination = "{{git_destination_dir}}"
# branch = "{{branch_name}}"
# requirements_file = "requirements.txt"
# setup_commands = [
#   "{{setup_command}}"
# ]

[[file]]
from_source = "https://raw.githubusercontent.com/RomlinGroup/Flatpack/main/warehouse/llama-cpp/custom.json"
to_destination = "custom.json"

[[file]]
from_source = "https://raw.githubusercontent.com/RomlinGroup/Flatpack/main/warehouse/llama-cpp/build.sh"
to_destination = "build.sh"

[[file]]
from_source = "https://raw.githubusercontent.com/RomlinGroup/Flatpack/main/warehouse/llama-cpp/device.sh"
to_destination = "device.sh"

[[run]]
command = "chmod +x"
file = "build.sh"

[[run]]
command = "chmod +x"
file = "device.sh"